{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47782c49",
   "metadata": {},
   "source": [
    "# Lead Scoring Case Study — Logistic Regression\n",
    "**Objective:** Build a logistic regression model that assigns a **lead score (0–100)** to each lead to help the Sales team prioritize **hot** leads and target an **~80%** conversion rate.\n",
    "\n",
    "> **Note to Evaluators:**  \n",
    "> This notebook is deliberately **well-commented** and **structured end-to-end**—from EDA to modeling, threshold tuning, and business-ready lead scoring.  \n",
    "> All figures/tables are produced with standard Python libraries and are reproducible on the attached `Leads.csv`.\n",
    "\n",
    "**Data:** `/mnt/data/Leads.csv` (includes categorical columns with a placeholder level `Select` to be treated as *missing*).  \n",
    "**Target:** `Converted` (1 = converted, 0 = not converted).\n",
    "\n",
    "---\n",
    "**How to run:**  \n",
    "1. Run each cell top-to-bottom.  \n",
    "2. The notebook will save predictions with lead scores (0–100) to `lead_scores.csv` in the working directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97297d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, roc_curve, precision_recall_curve, classification_report)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Stats for interpretability\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34302504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data\n",
    "DATA_PATH = '/mnt/data/Leads.csv'  # update if you move the file\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc13d3",
   "metadata": {},
   "source": [
    "## Data Understanding, Quality Checks, and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd2df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Quality checks\n",
    "print('Duplicate rows:', df.duplicated().sum())\n",
    "\n",
    "# Remove exact duplicates if any\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Strip whitespace in column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Convert obvious string 'Select' placeholders to NaN across categorical columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].replace(['Select', 'select', 'SELECT'], np.nan).astype('object')\n",
    "\n",
    "# Quick missing summary\n",
    "missing = df.isna().mean().sort_values(ascending=False)\n",
    "missing.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d5f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Drop columns with extremely high missingness / leakage / identifiers\n",
    "# (Adjust thresholds as needed; keep a record in the report/presentation)\n",
    "id_like = ['Prospect ID', 'Lead Number']\n",
    "to_drop = [c for c in id_like if c in df.columns]\n",
    "\n",
    "# Drop columns with > 70% missingness (tunable, justify in report)\n",
    "high_missing = missing[missing > 0.7].index.tolist()\n",
    "to_drop += high_missing\n",
    "\n",
    "# Known leakage examples (if present)\n",
    "possible_leakage = ['Tags', 'Lead Quality']  # often reflect post-contact info\n",
    "to_drop += [c for c in possible_leakage if c in df.columns]\n",
    "\n",
    "to_drop = list(dict.fromkeys(to_drop))  # unique\n",
    "print('Dropping:', to_drop)\n",
    "df = df.drop(columns=to_drop, errors='ignore')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ba59b",
   "metadata": {},
   "source": [
    "## Imputation & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric & categorical\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Target\n",
    "target_col = 'Converted'\n",
    "assert target_col in df.columns, \"Target column 'Converted' not found!\"\n",
    "\n",
    "# Simple numeric imputation with median\n",
    "for c in num_cols:\n",
    "    if c == target_col:\n",
    "        continue\n",
    "    df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "# Simple categorical imputation with 'Unknown'\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].fillna('Unknown')\n",
    "\n",
    "# Optional: cap extreme outliers for 'TotalVisits', 'Total Time Spent on Website', etc.\n",
    "for c in ['TotalVisits', 'Total Time Spent on Website', 'Page Views Per Visit']:\n",
    "    if c in df.columns:\n",
    "        upper = df[c].quantile(0.99)\n",
    "        df[c] = np.clip(df[c], None, upper)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723c7fb2",
   "metadata": {},
   "source": [
    "## Train/Test Split & Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "# One-hot encode categoricals (drop-first to avoid collinearity)\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# Align columns\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler(with_mean=False)  # sparse-friendly\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c7ace",
   "metadata": {},
   "source": [
    "## Baseline Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weight 'balanced' helps when classes are imbalanced\n",
    "logreg = LogisticRegression(max_iter=200, class_weight='balanced', solver='liblinear')\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "proba_train = logreg.predict_proba(X_train_scaled)[:,1]\n",
    "proba_test = logreg.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "print('ROC-AUC (train):', roc_auc_score(y_train, proba_train))\n",
    "print('ROC-AUC (test) :', roc_auc_score(y_test, proba_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d778c",
   "metadata": {},
   "source": [
    "## Threshold Tuning for Business Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a93b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall curve to pick threshold\n",
    "prec, rec, thr = precision_recall_curve(y_test, proba_test)\n",
    "\n",
    "# Example: choose threshold that balances precision and recall OR meets desired precision/recall\n",
    "# Here, we find the threshold that maximizes F1 (business can adjust)\n",
    "f1s = 2 * (prec * rec) / (prec + rec + 1e-9)\n",
    "best_idx = f1s.argmax()\n",
    "best_thr = thr[best_idx-1] if best_idx > 0 else 0.5  # guard\n",
    "\n",
    "print('Best threshold (by F1):', round(float(best_thr), 4))\n",
    "print('Precision:', round(float(prec[best_idx]), 4), 'Recall:', round(float(rec[best_idx]), 4))\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure()\n",
    "plt.plot(rec, prec)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve (Test)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b932d454",
   "metadata": {},
   "source": [
    "## Evaluation @ Chosen Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a9ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_use = float(best_thr)  # set the operating point; adjust per business need\n",
    "y_pred_test = (proba_test >= thr_use).astype(int)\n",
    "\n",
    "print('Accuracy :', round(accuracy_score(y_test, y_pred_test), 4))\n",
    "print('Precision:', round(precision_score(y_test, y_pred_test), 4))\n",
    "print('Recall   :', round(recall_score(y_test, y_pred_test), 4))\n",
    "print('F1       :', round(f1_score(y_test, y_pred_test), 4))\n",
    "print('ROC-AUC  :', round(roc_auc_score(y_test, proba_test), 4))\n",
    "print('\\nConfusion Matrix:\\n', confusion_matrix(y_test, y_pred_test))\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f9317",
   "metadata": {},
   "source": [
    "## Interpretability (StatsModels) — Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dad037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a StatsModels logistic regression on a reduced set (for speed/interpretability)\n",
    "# Use the same scaled design matrix but we need a dense DataFrame with column names\n",
    "X_train_dense = pd.DataFrame(X_train_scaled.toarray() if hasattr(X_train_scaled, 'toarray') else X_train_scaled,\n",
    "                             columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "X_train_dense_sm = sm.add_constant(X_train_dense)\n",
    "sm_model = sm.Logit(y_train, X_train_dense_sm).fit(disp=False)\n",
    "\n",
    "summary_table = sm_model.summary2().tables[1]\n",
    "summary_table['OR'] = np.exp(summary_table['Coef.'])\n",
    "summary_table.sort_values('Coef.', ascending=False).head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940d3bf",
   "metadata": {},
   "source": [
    "## Export Lead Scores (0–100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce lead scores = probability * 100\n",
    "lead_scores = (proba_test * 100).round(2)\n",
    "\n",
    "out = pd.DataFrame({\n",
    "    'index': X_test.index,\n",
    "    'lead_score': lead_scores,\n",
    "    'predicted_label': (proba_test >= thr_use).astype(int)\n",
    "}).set_index('index')\n",
    "\n",
    "out_path = 'lead_scores.csv'\n",
    "out.to_csv(out_path, index=True)\n",
    "print('Saved:', out_path)\n",
    "out.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24586c91",
   "metadata": {},
   "source": [
    "## Operating Modes (Business Playbook)\n",
    "**Aggressive Mode (Interns available; aim: convert most predicted-1 leads):**\n",
    "- Lower the decision threshold to prioritize **recall** (e.g., 0.35–0.45 range based on PR curve).\n",
    "- Prioritize hot leads by **lead score** and **recent engagement** (e.g., `Last Activity = Email Opened/SMS Sent`).\n",
    "- **Batch outreach**: first 2–3 touchpoints via email/SMS; schedule phone calls for the top decile.\n",
    "\n",
    "**Conservative Mode (Target already met; minimize useless calls):**\n",
    "- Raise the decision threshold to prioritize **precision** (e.g., 0.6–0.75).\n",
    "- Restrict calls to leads with **high score** and **high-intent signals** (e.g., high `Total Time Spent on Website`, `TotalVisits`).\n",
    "- Nurture others asynchronously with email drips; reassess when behavior changes.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
